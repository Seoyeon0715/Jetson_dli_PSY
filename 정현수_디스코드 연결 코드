#디스코드

import gradio as gr
import pandas as pd
import serial
import time
import json
import requests
from openai import OpenAI

# OpenAI API 키 설정
OpenAI.api_key = "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"

# 디스코드 웹훅 URL 설정
WEBHOOK_URL = "https://discord.com/api/webhooks/your_webhook_id/your_webhook_token"

def send_to_discord(message, webhook_url):
    """
    디스코드로 메시지를 전송하는 함수
    :param message: 전송할 메시지
    :param webhook_url: 디스코드 웹훅 URL
    """
    try:
        data = {"content": message}
        response = requests.post(webhook_url, json=data)
        if response.status_code == 204:
            print("메시지가 성공적으로 전송되었습니다.")
        else:
            print(f"전송 실패! 상태 코드: {response.status_code}, 응답: {response.text}")
    except Exception as e:
        print(f"오류 발생: {e}")

def moisture_sensor_info(mode='real-time', file_path=None, port='/dev/ttyUSB0', baudrate=9600):
    """
    토양 수분 센서 데이터를 처리하고 반환하는 함수.
    """
    if mode == 'real-time':
        try:
            arduino = serial.Serial(port, baudrate, timeout=1)
            if arduino.in_waiting > 0:
                data = arduino.readline().decode('utf-8').strip()
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                arduino.close()
                return {'timestamp': timestamp, 'moisture': f"{data}%"}
            else:
                return {'error': 'No data available from sensor.'}
        except Exception as e:
            return {'error': str(e)}

    elif mode == 'file':
        try:
            if not file_path:
                return {'error': 'File path is required in file mode.'}
            df = pd.read_excel(file_path)
            if df.empty:
                return {'error': 'No data available in the file.'}
            latest_entry = df.iloc[-1].to_dict()
            return {'timestamp': latest_entry['Timestamp'], 'moisture': f"{latest_entry['Moisture (%)']}%"}
        except Exception as e:
            return {'error': str(e)}

    else:
        return {'error': 'Invalid mode. Use "real-time" or "file".'}

def light_sensor_info(mode='real-time', file_path=None, port='/dev/ttyUSB0', baudrate=9600):
    """
    조도 센서 데이터를 처리하고 반환하는 함수.
    """
    if mode == 'real-time':
        try:
            arduino = serial.Serial(port, baudrate, timeout=1)
            time.sleep(2)
            if arduino.in_waiting > 0:
                data = arduino.readline().decode("utf-8").strip()
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                arduino.close()
                return {'timestamp': timestamp, 'brightness': f"{data.split(': ')[1]}%"}
            else:
                return {'error': 'No data available from sensor.'}
        except Exception as e:
            return {'error': str(e)}

    elif mode == 'file':
        try:
            if not file_path:
                return {'error': 'File path is required in file mode.'}
            df = pd.read_excel(file_path)
            if df.empty:
                return {'error': 'No data available in the file.'}
            latest_entry = df.iloc[-1].to_dict()
            return {'timestamp': latest_entry['Timestamp'], 'brightness': f"{latest_entry['Brightness (%)']}%"}
        except Exception as e:
            return {'error': str(e)}

    else:
        return {'error': 'Invalid mode. Use "real-time" or "file".'}

def ask_openai(llm_model, messages, user_message, functions):
    client = OpenAI()
    proc_messages = messages

    if user_message:
        proc_messages.append({"role": "user", "content": user_message})

    response = client.chat.completions.create(model=llm_model, messages=proc_messages, tools=functions, tool_choice="auto")
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    if tool_calls:
        available_functions = {
            "moisture_sensor_info": moisture_sensor_info,
            "light_sensor_info": light_sensor_info
        }

        proc_messages.append(response_message)

        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            function_response = function_to_call(**function_args)

            proc_messages.append({
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": function_name,
                "content": function_response,
            })

            # 디스코드 알림 전송
            send_to_discord(f"센서 데이터 알림: {function_response}", WEBHOOK_URL)

        second_response = client.chat.completions.create(model=llm_model, messages=proc_messages)
        assistant_message = second_response.choices[0].message.content
    else:
        assistant_message = response_message.content

    proc_messages.append({"role": "assistant", "content": assistant_message})
    return proc_messages, assistant_message

messages = []

def process(user_message, chat_history):
    proc_messages, ai_message = ask_openai("gpt-4o-mini", messages, user_message, functions=sensor_functions)
    chat_history.append((user_message, ai_message))
    return "", chat_history

with gr.Blocks() as demo:
    chatbot = gr.Chatbot(label="센서 데이터 조회")
    user_textbox = gr.Textbox(label="입력")
    user_textbox.submit(process, [user_textbox, chatbot], [user_textbox, chatbot])

demo.launch(share=True, debug=True)
